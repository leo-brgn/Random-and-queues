---
title: "Rapport"
output: pdf_document
date: '2022-03-07'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# installation du package randtoolbox s'il n'est pas installe
if(!require(randtoolbox)) install.packages("randtoolbox")
# chargement du package randtoolbox
library(randtoolbox)
# chargement du module generateurs.R
# source('~/Documents/INSA/IFA3/PROB/TP-Probas/generateurs.R')
source('generateurs.R')

# definition des parametres
sVN <- 3454 # graine pour la methode de Von Neumann
sMT <- 1502 # graine pour la methode de Mersenne-Twister
Nsimu <- 1000 # nombre de simulations (nombre d'entiers par sequences generee)
Nrepet <- 20 # nombre de repetitions (nombre de sequences generees)
```

## Partie 1 : Tests de générateurs pseudo-aléatoires

### Question 2.1

```{r, echo=FALSE}
# appel des fonctions de génréations de nombres aléatoires :
vn <- VonNeumann(Nsimu, Nrepet, sVN) 
mt <- MersenneTwister(Nsimu, Nrepet, sMT)
ru <- randu(Nsimu, Nrepet, sVN)
stm <- standardMinimal(Nsimu, Nrepet, sVN)

# max valeur possible 
max_mersenne <- 2^32-1
max_vn <- 9999
max_ru <- 2^31-1
max_stm <- 2^31-2

# Visualiation de donnees generees sous forme des histogrammes (1ere colonne) 
# sur le meme graphique
par(mfrow=c(2,2)) #
hist(vn[,1], breaks=seq(0,max_vn,length=20), xlab='', main='Von Neumann')
hist(mt[,1], breaks=seq(0,max_mersenne,length=20), xlab='', 
     main='Mersenne Twister')
hist(ru[,1], breaks=seq(0,max_ru,length=20), xlab='', main='RANDU')
hist(stm[,1], breaks=seq(0,max_stm,length=20), xlab='', 
     main='Standad Minimal')

```

La méthode de Von Neumann ne semble pas satisfaisante pour générer des nombres aléatoires suivant une loi uniforme. On peut remarquer des valeurs absorbantes. Les trois autres méthodes semblent quant à elles fournir des résultats plutôt satisfaisants. On peut supposer d'après le graphique que l'écart-type est assez faible pour ces trois méthodes.

### Question 2.2

```{r, echo=FALSE}
# Visualiation de donnees generees sous forme des nuages des points (scatterplot) 
# sur le meme graphique
# chaque donnee est prise en fonction de la donnee precedente
par(mfrow=c(2,2))
plot(vn[1:(Nsimu-1),1], vn[2:Nsimu,1], xlab='VN(i)', ylab='VN(i+1)', 
     main='Von Neumann')
plot(mt[1:(Nsimu-1),1], mt[2:Nsimu,1], xlab='MT(i)', ylab='MT(i+1)', 
     main='Mersenne Twister')
plot(ru[1:(Nsimu-1),1], ru[2:Nsimu,1], xlab='RU(i)', ylab='RU(i+1)', 
     main='RANDU')
plot(stm[1:(Nsimu-1),1], stm[2:Nsimu,1], xlab='STM(i)', ylab='STM(i+1)', 
     main='Standard Minimal')
```

Ce mode de visualisation nous permet de voir si la valeur donnée par l'algorithme dépend ou non de la valeur précédente. On remarque que pour tous les algorithmes sauf celui de Von Neumann, il ne semble pas y avoir de corrélation entre les valeurs de rang N et N+1. En effet, on ne voit pas de courbe ou de droite se dessiner et les valeurs sont au contraire très dispersées sur les graphiques.

### Question 3

Initialisation des données pour les tests:
```{r}
# Initialisation des vecteurs de tests avec les vecteurs déjà générés
vec_mt <- mt
vec_vn <- vn
vec_ru <- ru
vec_stm <- stm
# génération des graines
graines <- sample.int(10000,25)
# génération des nombres aléatoires pour chaque graine et pour chaque algorithme
for (i in 1:25)
{
  vec_mt <- append(vec_mt, MersenneTwister(Nsimu, Nrepet, graines[i]))
  vec_vn <- append(vec_vn, VonNeumann(Nsimu, Nrepet, graines[i]))
  vec_ru <- append(vec_ru, randu(Nsimu, Nrepet, graines[i]))
  vec_stm <- append(vec_stm, standardMinimal(Nsimu, Nrepet, graines[i]))
}
```

Fonctions Frequency (appliquée sur le vecteur x) :
```{r}
Frequency <- function(x, nb)
{
  s_obs <- rep(0, length(x))
  
  for (i in 1:length(x))
  {
    bit_x <- rev(binary(x[i]))
    s <- 0
    for (j in 1:nb)
    {
      if (bit_x[j] == 0)
      {
        s <- s - 1
      } else {
        s <-s + 1
      }
    }
    s <- abs(s)
    s_obs[i] <- s / sqrt(nb)
  }
  return(s_obs)
}
```

Test de la fonction sur les différents algorithmes :

```{r}
# Test de fréquence monobit
fr_mt <- Frequency(vec_mt,32)
fr_vn <- Frequency(vec_vn,14)
fr_ru <- Frequency(vec_ru,31)
fr_stm <- Frequency(vec_stm,31)

p_mt <- 2 * (1-pnorm(fr_mt))
p_mt <- sum(p_mt)/length(p_mt)
p_vn <- 2 * (1-pnorm(fr_vn))
p_vn <- sum(p_vn)/length(p_vn)
p_ru <- 2 * (1-pnorm(fr_ru))
p_ru <- sum(p_ru)/length(p_ru)
p_stm <- 2 * (1-pnorm(fr_stm))
p_stm<- sum(p_stm)/length(p_stm)
```

| Algorithme | Von Neumann | Mersenne Twister | RANDU | Standard minimal |
|------------|-------------|------------------|-------|------------------|
| P_valeur   | 0.00018     | 0.506            | 0.498 | 0.495            |

Pour valider l'hypothèse que l'algorithme produit une séquence aléatoire, il faut 
que P_valeur soit strictement supérieur à 0.01. De ce fait, l'algorithme de Von
Neumann n'est clairment pas satisfaisant. Toutefois les trois autres algorithmes
le sont.


### Question 4

Fonction Runs (retourne un vecteur avec la valeur p pour chaque valeur du vecteur x) :
```{r}
Runs <- function(x, nb)
{
  p_vals <- rep(0, length(x))
  tau = 2 / sqrt(nb)

  for (i in 1:length(x))
  {
    bit_x <- rev(binary(x[i]))
    Pi <- sum(bit_x[1:nb])
    Pi <- Pi / nb
    if (Pi - 0.5 >= tau)
    {
      p_vals[i] = 0
    } else {
      v <- sum(bit_x[1:nb]) + 1
      p_vals[i] <- 2 * (1-pnorm((abs(v - 2 * nb * Pi * (1-Pi)))/(2*sqrt(nb)*Pi*(1-Pi))))
      
    }
  }
  return(p_vals)
}
``` 

Test de la fonction sur les différents algorithmes:

```{r}
# Test des runs
p_mt <- Runs(mt,32)
p_vn <- Runs(vn,14)
p_ru <- Runs(ru,31)
p_stm <- Runs(stm,31)
p_mt <- mean(p_mt < 0.01)
p_vn <- mean(p_vn < 0.01)
p_ru <- mean(p_ru < 0.01)
p_stm <- mean(p_stm < 0.01)
```

| Algorithme | Von Neumann | Mersenne Twister | RANDU | Standard minimal |
|------------|-------------|------------------|-------|------------------|
| P_valeur   | 0%          | 5.36%            | 9.28% | 7.457%           |

Encore une fois on remarque que l'algorithme de Von Neumann ne permet pas de 
produire des nombres aléatoires.

### Question 5
```{r}
# Tests d'ordre
order.test(vec_mt, d = 4, echo = FALSE)$p.value
order.test(vec_vn, d = 4, echo = FALSE)$p.value
order.test(vec_ru, d = 4, echo = FALSE)$p.value
order.test(vec_stm, d = 4, echo = FALSE)$p.value
```

| Algorithme | Von Neumann | Mersenne Twister | RANDU | Standard minimal |
|------------|-------------|------------------|-------|------------------|
| P_valeur   | 0           | 0.65             | 0.81  | 0.59             |

On peut tirer de ce test les mêmes conclusions qu'à la question précédente.

## Partie 2 : Simulations de lois de probabilités quelconques

### Question bonus 1

Fonction représentant la loi binomiale (compte le nombre de succès):
```{r}
LoiBinomiale <- function(n, p)
{
  sum <- 0
  for (i in 1:n)
  {
    if (runif(1) <= p)
      sum <- sum + 1
  }
  return(sum)
}
```

Test de la fonction pour n = 10 et p = 0.7 (sur 1000 réalisations) et comparaison
du résultat obtenu avec la densité de la loi Gaussienne N(np, np(1-p)) :

```{r}
# initialisation
n <- 10
p <- 0.7
# réalisations
valeurs <- array(numeric(),c(0))
for (i in 1:1000) {
  valeurs <- append(valeurs, LoiBinomiale(n, p))
}
# calcul de la gaussienne pour des valeurs discrètes
gaussienne <- array(numeric(), c(0))
for (i in 1:15) {
  gaussienne <- append(gaussienne, dnorm(i, n*p, sqrt(n*p*(1-p))) * 1000)
}

par(mfrow=c(1,1))
plot(table(valeurs), 
     col="blue",
     xlab = "nombre de succès",
     ylab = "nombre de réalisations",
     main = "Loi binomiale (n=10, p=0.7)")

lines(gaussienne,
      lwd = 2,
      col = "chocolate3")
```

On peut voir que les résultats calculés pour la loi binomiale correspondent plutôt
bien à la courbe de la gaussienne.









